{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0dcd572-b896-4e17-96e5-df6f327e8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df1 = pd.read_csv(r\"D:\\1st week\\aapl.us.txt\")\n",
    "df2 = pd.read_csv(r\"D:\\1st week\\amzn.us.txt\")\n",
    "df3 = pd.read_csv(r\"D:\\1st week\\googl.us.txt\")\n",
    "df4 = pd.read_csv(r\"D:\\1st week\\msft.us.txt\")\n",
    "df5 = pd.read_csv(r\"D:\\1st week\\tsla.us.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34277e7-578e-40f6-867b-6c0db26f8b82",
   "metadata": {},
   "source": [
    "\n",
    "# Now we will check for \"NaN values\"\n",
    "\n",
    "* We will use `isnull().sum()` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6babf813-43b9-4a95-bb89-e52a4f1ee135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "Date       0\n",
      "Open       0\n",
      "High       0\n",
      "Low        0\n",
      "Close      0\n",
      "Volume     0\n",
      "OpenInt    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "AMZN\n",
      "Date       0\n",
      "Open       0\n",
      "High       0\n",
      "Low        0\n",
      "Close      0\n",
      "Volume     0\n",
      "OpenInt    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "GOOGL\n",
      "Date       0\n",
      "Open       0\n",
      "High       0\n",
      "Low        0\n",
      "Close      0\n",
      "Volume     0\n",
      "OpenInt    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "MSFT\n",
      "Date       0\n",
      "Open       0\n",
      "High       0\n",
      "Low        0\n",
      "Close      0\n",
      "Volume     0\n",
      "OpenInt    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "TSLA\n",
      "Date       0\n",
      "Open       0\n",
      "High       0\n",
      "Low        0\n",
      "Close      0\n",
      "Volume     0\n",
      "OpenInt    0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = {\"AAPL\":df1,\"AMZN\":df2,\"GOOGL\":df3,\"MSFT\":df4,\"TSLA\":df5}\n",
    "for i in dfs:\n",
    "     print(i)\n",
    "     print(dfs[i].isnull().sum())\n",
    "     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2aba26-33a2-4f45-8dc5-370002abcf3f",
   "metadata": {},
   "source": [
    "* Now we can see that there is no NaN values in each ticker , so there is no need of interpolation or ffill\n",
    "* Now we will convert the Date column to datetime format and then we will sort data by date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14588752-4ae7-49b5-9b69-95c4691ee338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "for i in dfs :\n",
    "    dfs[i]['Date'] = pd.to_datetime(dfs[i]['Date'])\n",
    "    dfs[i] = dfs[i].sort_values('Date')\n",
    "    print(dfs[i]['Date'].dtypes) #checking for succesfull conversion into date time format\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72654705-e362-4e3d-ab2b-648ab6040788",
   "metadata": {},
   "source": [
    "\n",
    "# Filtering the data\n",
    "\n",
    "* Now we will use filter the data from 2007 to 2017 using `between()` function\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c105f79-5eb5-420a-abdf-8a2e9b5c525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfs:\n",
    "    dfs[i] = dfs[i][dfs[i]['Date'].between(pd.Timestamp(\"2007-01-01\"), pd.Timestamp(\"2017-01-01\"))]\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149913f3-02b0-4942-b53f-35f468ca1527",
   "metadata": {},
   "source": [
    "\n",
    "# Adding the Daily return column\n",
    "\n",
    "* We will use `assign()` to add column and `pct_change()` to calculate percentage change in closing price\n",
    "* We know that first value of daily return will be NaN , so we will use `fillna()` function to fill that value with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e708d-15b4-4f5c-b971-2f4caaf6a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfs :\n",
    "    dfs[i] = dfs[i].assign(Daily_Return = dfs[i]['Close'].pct_change().fillna(0))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d04789-2bff-4a6f-af76-064bb32ee890",
   "metadata": {},
   "source": [
    "\n",
    "# Adding the 7-day Moving average,30-day Moving average,Rolling Volatility(30d)\n",
    "\n",
    "* We will use `rolling()` function and will make moving window according to the requirement and will set min_period = 1 otherwise it will show NaN values in starting\n",
    "* We will use `std()` and `mean()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd106c1-d131-4648-bccd-7333a9eecf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfs:\n",
    "    dfs[i] = dfs[i].assign(Mov_average_7 = dfs[i]['Close'].rolling(7,min_periods=1).mean(),\n",
    "                           Mov_average_30 = dfs[i]['Close'].rolling(30,min_periods = 1).mean(),\n",
    "                           Rol_vol_30 = dfs[i]['Daily_Return'].rolling(30,min_periods = 1).std().fillna(0))\n",
    "   \n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18642c49-2780-43e3-868c-e60116ac5669",
   "metadata": {},
   "source": [
    "* Now we will find highest average return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b5ed88-0846-4cf8-8321-1b8a4ca6253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n"
     ]
    }
   ],
   "source": [
    "high = -float('inf')\n",
    "for i in dfs:\n",
    "    avg = dfs[i]['Daily_Return'].mean()\n",
    "    if avg >= high :\n",
    "        high = avg\n",
    "        stock = i\n",
    "print(stock)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dee304-cb4a-42c2-b7b9-7553a0fc60e3",
   "metadata": {},
   "source": [
    "* TSLA has the highest average return\n",
    "* Now we will find the most volatile month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e9261aa-c492-45a4-8b6c-eea46894350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-06-29 00:00:00\n",
      "TSLA\n"
     ]
    }
   ],
   "source": [
    "high = -float('inf')\n",
    "for i in dfs:\n",
    "    most_volatile = dfs[i]['Rol_vol_30'].max()\n",
    "    if most_volatile >= high :\n",
    "        high = most_volatile\n",
    "        date = dfs[i]['Date'][dfs[i]['Rol_vol_30'].idxmax()]\n",
    "        stocks = i\n",
    "print(date)\n",
    "print(stocks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
